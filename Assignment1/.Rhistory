library(zoo)
library(ggplot2)
library(tseries)
library(stats)
library(lmtest)
library(Metrics)
library(dynlm)
library(dLagM)
library(tsoutliers)
# Load data
data <- read.csv("data_assign_p1.csv")
fmt <- "%YQ%q"
data$obs <- as.yearqtr(data$obs, format = fmt)
ggplot(data, aes(obs, GDP_QGR)) +
geom_point() +
geom_line() +
scale_x_yearqtr(format = fmt)
Acf(
data$GDP_QGR,
lag.max = 12
)
Pacf(
data$GDP_QGR,
lag.max = 12
)
ar4 <- arima(data$GDP_QGR, order = c(4,0,0))
coeftest(ar4)
ar3 <- arima(data$GDP_QGR, order = c(3,0,0))
coeftest(ar3)
ar2 <- arima(data$GDP_QGR, order = c(2,0,0))
coeftest(ar2)
ar1 <- arima(data$GDP_QGR, order = c(1,0,0))
coeftest(ar1)
checkresiduals(ar1)
seriesdata <- ts(data$GDP_QGR, start= c(1987, 2), end = c(2009, 1), frequency = 4)
forecast1 <- ts(predict(ar1, n.ahead=8)$pred, start = c(2009,2), frequency = 4)
forecast1
ts.plot(forecast1, type="l")
ts.plot(seriesdata, xlim = c(1987, 2011))
se1 <- ts(predict(ar1, n.ahead=8)$se, start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
ts.plot(seriesdata, xlim = c(2005, 2011))
se1 <- ts(predict(ar1, n.ahead=8)$se, start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
pnorm(0, mean=forecast1[1], sd = se1[1])
jarque.bera.test(ar1$residuals)
ts.plot(seriesdata, xlim = c(1987, 2011))
re <- ts(c(-1.63,0.28, 0.33, 0.66, 1.59, 0.51, 0.71, 0.81), start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
points(re, type="l", col=3)
ts.plot(seriesdata, xlim = c(2005, 2011))
re <- ts(c(-1.63,0.28, 0.33, 0.66, 1.59, 0.51, 0.71, 0.81), start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
points(re, type="l", col=3)
ar3
ts.plot(seriesdata, xlim = c(1987,2011))
forecast3 <- ts(predict(ar3, n.ahead=8)$pred, start = c(2009,2), frequency = 4)
se3 <- ts(predict(ar3, n.ahead=8)$se, start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
points(forecast3, type="l", col=4)
points(forecast3 - 1.96*se3, type="l", col=4, lty=2)
points(forecast3 + 1.96*se3, type="l", col=4, lty=2)
points(re, type="l", col=3)
ts.plot(seriesdata, xlim = c(2005,2011))
forecast3 <- ts(predict(ar3, n.ahead=8)$pred, start = c(2009,2), frequency = 4)
se3 <- ts(predict(ar3, n.ahead=8)$se, start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
points(forecast3, type="l", col=4)
points(forecast3 - 1.96*se3, type="l", col=4, lty=2)
points(forecast3 + 1.96*se3, type="l", col=4, lty=2)
points(re, type="l", col=3)
rmse(re, forecast1)
rmse(re, forecast3)
error1 <-  re - forecast1
error3 <- re - forecast3
dm.test(error1, error3)
# Load data
data2 <- read.csv("data_assign_p2.csv")
fmt <- "%YQ%q"
data2$obs <- as.yearqtr(data2$obs, format = fmt)
ggplot(data2, aes(obs, GDP_QGR)) +
geom_point() +
geom_line() +
scale_x_yearqtr(format = fmt)
ggplot(data2, aes(obs, UN_RATE)) +
geom_point() +
geom_line() +
scale_x_yearqtr(format = fmt)
data3 = data2
data3$GDP_QGR <- ts(data3$GDP_QGR, start = c(1987,2), frequency = 4)
data3$UN_RATE <- ts(data3$UN_RATE, start = c(1987,2), frequency = 4)
gdp4 <- arima(data3$GDP_QGR, order = c(4,0,0))
coeftest(gdp4)
gdp3 <- arima(data3$GDP_QGR, order = c(3,0,0))
coeftest(gdp3)
adl4_4 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:4) + L(data3$GDP_QGR, 0:4))
coeftest(adl4_4)
adl3_3 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:3) + L(data3$GDP_QGR, 0:3))
coeftest(adl3_3)
adl3_2 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:3) + L(data3$GDP_QGR, 0:2))
coeftest(adl3_2)
adl3_1 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:3) + L(data3$GDP_QGR, 0:1))
coeftest(adl3_1)
adl3_0 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:3) + L(data3$GDP_QGR, 0:0))
coeftest(adl3_0)
adl2_0 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:3) + L(data3$GDP_QGR, 1:1))
coeftest(adl2_0)
adl3_1 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, c(1,3)) + L(data3$GDP_QGR, 1:1))
coeftest(adl3_1)
as.numeric(adl3_1$coefficients[2]*adl3_1$coefficients[4])
as.numeric(adl3_1$coefficients[1]/(1-adl3_1$coefficients[2]-adl3_1$coefficients[3]))
as.numeric(adl3_1$coefficients[4]/(1-adl3_1$coefficients[2]-adl3_1$coefficients[3]))
as.numeric(gdp3$coef[4]/(1-gdp3$coef[1]-gdp3$coef[2]-gdp3$coef[3]))
as.numeric(adl3_1$coefficients[1]/(1-adl3_1$coefficients[2]-adl3_1$coefficients[3])) + as.numeric(adl3_1$coefficients[4]/(1-adl3_1$coefficients[2]-adl3_1$coefficients[3])) * as.numeric(gdp3$coef[4]/(1-gdp3$coef[1]-gdp3$coef[2]-gdp3$coef[3]))
h = 8
forecast_ar <-predict(gdp3, n.ahead=h)$pred
forecast_ar
forecast_ar <- as.numeric(forecast_ar)
GDP_QGR <- append(as.numeric(data2$GDP_QGR), forecast_ar)
UN_RATE <- append(as.numeric(data2$UN_RATE), numeric(h))
n <- length(data2$obs)
for (i in 1:h){
j = i + n
UN_RATE[j] <- adl3_1$coefficient[1] + adl3_1$coefficient[2] * UN_RATE[j-1] + adl3_1$coefficient[3] * UN_RATE[j-3] + adl3_1$coefficient[4] * GDP_QGR[j-1]
}
fe1 <- summary(adl3_1)$sigma
"The probability that it is below 7.8:"
pnorm(7.8, mean = UN_RATE[109], sd = fe1)
"The probability that it is above 7.8:"
1 - pnorm(7.8, mean = UN_RATE[109], sd = fe1)
jarque.bera.test(adl3_1$residuals)
UN$test
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
library(TSstudio)
library(stringr)
library(zoo)
library(ggplot2)
library(tseries)
library(stats)
library(lmtest)
library(Metrics)
library(dynlm)
library(dLagM)
library(tsoutliers)
# Load data
data <- read.csv("data_assign_p1.csv")
fmt <- "%YQ%q"
data$obs <- as.yearqtr(data$obs, format = fmt)
ggplot(data, aes(obs, GDP_QGR)) +
geom_point() +
geom_line() +
scale_x_yearqtr(format = fmt)
Acf(
data$GDP_QGR,
lag.max = 12
)
Pacf(
data$GDP_QGR,
lag.max = 12
)
ar4 <- arima(data$GDP_QGR, order = c(4,0,0))
coeftest(ar4)
ar3 <- arima(data$GDP_QGR, order = c(3,0,0))
coeftest(ar3)
ar2 <- arima(data$GDP_QGR, order = c(2,0,0))
coeftest(ar2)
ar1 <- arima(data$GDP_QGR, order = c(1,0,0))
coeftest(ar1)
checkresiduals(ar1)
seriesdata <- ts(data$GDP_QGR, start= c(1987, 2), end = c(2009, 1), frequency = 4)
forecast1 <- ts(predict(ar1, n.ahead=8)$pred, start = c(2009,2), frequency = 4)
forecast1
ts.plot(forecast1, type="l")
ts.plot(seriesdata, xlim = c(1987, 2011))
se1 <- ts(predict(ar1, n.ahead=8)$se, start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
ts.plot(seriesdata, xlim = c(2005, 2011))
se1 <- ts(predict(ar1, n.ahead=8)$se, start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
pnorm(0, mean=forecast1[1], sd = se1[1])
jarque.bera.test(ar1$residuals)
ts.plot(seriesdata, xlim = c(1987, 2011))
re <- ts(c(-1.63,0.28, 0.33, 0.66, 1.59, 0.51, 0.71, 0.81), start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
points(re, type="l", col=3)
ts.plot(seriesdata, xlim = c(2005, 2011))
re <- ts(c(-1.63,0.28, 0.33, 0.66, 1.59, 0.51, 0.71, 0.81), start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
points(re, type="l", col=3)
ar3
ts.plot(seriesdata, xlim = c(1987,2011))
forecast3 <- ts(predict(ar3, n.ahead=8)$pred, start = c(2009,2), frequency = 4)
se3 <- ts(predict(ar3, n.ahead=8)$se, start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
points(forecast3, type="l", col=4)
points(forecast3 - 1.96*se3, type="l", col=4, lty=2)
points(forecast3 + 1.96*se3, type="l", col=4, lty=2)
points(re, type="l", col=3)
ts.plot(seriesdata, xlim = c(2005,2011))
forecast3 <- ts(predict(ar3, n.ahead=8)$pred, start = c(2009,2), frequency = 4)
se3 <- ts(predict(ar3, n.ahead=8)$se, start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
points(forecast3, type="l", col=4)
points(forecast3 - 1.96*se3, type="l", col=4, lty=2)
points(forecast3 + 1.96*se3, type="l", col=4, lty=2)
points(re, type="l", col=3)
rmse(re, forecast1)
rmse(re, forecast3)
error1 <-  re - forecast1
error3 <- re - forecast3
dm.test(error1, error3)
# Load data
data2 <- read.csv("data_assign_p2.csv")
fmt <- "%YQ%q"
data2$obs <- as.yearqtr(data2$obs, format = fmt)
ggplot(data2, aes(obs, GDP_QGR)) +
geom_point() +
geom_line() +
scale_x_yearqtr(format = fmt)
ggplot(data2, aes(obs, UN_RATE)) +
geom_point() +
geom_line() +
scale_x_yearqtr(format = fmt)
data3 = data2
data3$GDP_QGR <- ts(data3$GDP_QGR, start = c(1987,2), frequency = 4)
data3$UN_RATE <- ts(data3$UN_RATE, start = c(1987,2), frequency = 4)
gdp4 <- arima(data3$GDP_QGR, order = c(4,0,0))
coeftest(gdp4)
gdp3 <- arima(data3$GDP_QGR, order = c(3,0,0))
coeftest(gdp3)
adl4_4 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:4) + L(data3$GDP_QGR, 0:4))
coeftest(adl4_4)
adl3_3 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:3) + L(data3$GDP_QGR, 0:3))
coeftest(adl3_3)
adl3_2 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:3) + L(data3$GDP_QGR, 0:2))
coeftest(adl3_2)
adl3_1 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:3) + L(data3$GDP_QGR, 0:1))
coeftest(adl3_1)
adl3_0 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:3) + L(data3$GDP_QGR, 0:0))
coeftest(adl3_0)
adl2_0 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:3) + L(data3$GDP_QGR, 1:1))
coeftest(adl2_0)
adl3_1 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, c(1,3)) + L(data3$GDP_QGR, 1:1))
coeftest(adl3_1)
as.numeric(adl3_1$coefficients[2]*adl3_1$coefficients[4])
as.numeric(adl3_1$coefficients[1]/(1-adl3_1$coefficients[2]-adl3_1$coefficients[3]))
as.numeric(adl3_1$coefficients[4]/(1-adl3_1$coefficients[2]-adl3_1$coefficients[3]))
as.numeric(gdp3$coef[4]/(1-gdp3$coef[1]-gdp3$coef[2]-gdp3$coef[3]))
as.numeric(adl3_1$coefficients[1]/(1-adl3_1$coefficients[2]-adl3_1$coefficients[3])) + as.numeric(adl3_1$coefficients[4]/(1-adl3_1$coefficients[2]-adl3_1$coefficients[3])) * as.numeric(gdp3$coef[4]/(1-gdp3$coef[1]-gdp3$coef[2]-gdp3$coef[3]))
h = 8
forecast_ar <-predict(gdp3, n.ahead=h)$pred
forecast_ar
forecast_ar <- as.numeric(forecast_ar)
GDP_QGR <- append(as.numeric(data2$GDP_QGR), forecast_ar)
UN_RATE <- append(as.numeric(data2$UN_RATE), numeric(h))
n <- length(data2$obs)
for (i in 1:h){
j = i + n
UN_RATE[j] <- adl3_1$coefficient[1] + adl3_1$coefficient[2] * UN_RATE[j-1] + adl3_1$coefficient[3] * UN_RATE[j-3] + adl3_1$coefficient[4] * GDP_QGR[j-1]
}
fe1 <- summary(adl3_1)$sigma
"The probability that it is below 7.8:"
pnorm(7.8, mean = UN_RATE[109], sd = fe1)
"The probability that it is above 7.8:"
1 - pnorm(7.8, mean = UN_RATE[109], sd = fe1)
jarque.bera.test(adl3_1$residuals)
UN_RATE <- ts(UN_RATE, start = c(1987, 2), frequency = 4)
UN <- ts_split(UN_RATE, sample.out = h)
ts.plot(UN$train, xlim = c(1987, 2017))
points(UN$test, type="l", col=2)
ts.plot(UN$train, xlim = c(2000, 2017))
points(UN$test, type="l", col=2)
h = 200
GDP_QGR <- append(rep(data2$GDP_QGR[n],3), numeric(h))
UN_RATE <- append(rep(data2$UN_RATE[n],3), numeric(h))
GDP_QGR[3+1] = 2
for (i in 1:h){
j = i + 3
GDP_QGR[j] <- GDP_QGR[j] + ar3$coef[4] + ar3$coef[1] * GDP_QGR[j-1] + ar3$coef[2] * GDP_QGR[j-2] + ar3$coef[3] * GDP_QGR[j-3]
}
n <- length(data2$obs)
for (i in 1:h){
j = i + 3
UN_RATE[j] <- adl3_1$coefficient[1] + adl3_1$coefficient[2] * UN_RATE[j-1] + adl3_1$coefficient[3] * UN_RATE[j-3] + adl3_1$coefficient[4] * GDP_QGR[j-1]
}
UN_RATE <- ts(UN_RATE, start = c(2013, 3), frequency = 4)
ts.plot(UN_RATE)
h = 200
GDP_QGR <- append(rep(data2$GDP_QGR[n],3), numeric(h))
UN_RATE <- append(rep(data2$UN_RATE[n],3), numeric(h))
GDP_QGR[3+1] = -2
for (i in 1:h){
j = i + 3
GDP_QGR[j] <- GDP_QGR[j] + ar3$coef[4] + ar3$coef[1] * GDP_QGR[j-1] + ar3$coef[2] * GDP_QGR[j-2] + ar3$coef[3] * GDP_QGR[j-3]
}
n <- length(data2$obs)
for (i in 1:h){
j = i + 3
UN_RATE[j] <- adl3_1$coefficient[1] + adl3_1$coefficient[2] * UN_RATE[j-1] + adl3_1$coefficient[3] * UN_RATE[j-3] + adl3_1$coefficient[4] * GDP_QGR[j-1]
}
UN_RATE <- ts(UN_RATE, start = c(2013, 3), frequency = 4)
ts.plot(UN_RATE)
"The obtained values are:"
UN$test
predict?
library(help = "stats")
library(help = "stats")
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
library(TSstudio)
library(stringr)
library(zoo)
library(ggplot2)
library(tseries)
library(stats)
library(lmtest)
library(Metrics)
library(dynlm)
library(dLagM)
library(tsoutliers)
# Load data
data <- read.csv("data_assign_p3.csv")
# Load data
data <- read.csv("data_assign_p3.csv")
View(data)
str(data)
set.seed(1)
size <- 200
# Create an empty array to hold our time series
x = numeric(size)
# Create the first value
x[1] <- rnorm(n = 1, mean = 0, sd = 1)
for (t in 2:size) {
# Create random noise for this observation
w.error = rnorm(n = 1, mean = 0, sd = 1)
# Compute the current value based on the previous value and the current noise
x[t] <- x[t - 1] + w.error
}
set.seed(1)
size <- 200
simulation <- 100
# Create an empty array to hold our time series
x = numeric(size)
simulation <- list()
# Create the first value
x[1] <- rnorm(n = 1, mean = 0, sd = 1)
for (i in 1:simulation){
for (t in 2:size) {
# Create random noise for this observation
w.error = rnorm(n = 1, mean = 0, sd = 1)
# Compute the current value based on the previous value and the current noise
x[t] <- x[t - 1] + w.error
}
simulation[i] <- x
}
set.seed(1)
size <- 200
simulation <- 100
# Create an empty array to hold our time series
x = numeric(size)
simulation <- list()
# Create the first value
x[1] <- rnorm(n = 1, mean = 0, sd = 1)
for (i in 1:simulation) {
for (t in 2:size) {
# Create random noise for this observation
w.error = rnorm(n = 1, mean = 0, sd = 1)
# Compute the current value based on the previous value and the current noise
x[t] <- x[t - 1] + w.error
}
simulation[i] <- x
}
set.seed(1)
t <- 200
n <- 100
# Create an empty array to hold our time series
x = numeric(size)
simulation <- list()
# Create the first value
x[1] <- rnorm(n = 1, mean = 0, sd = 1)
for (i in 1:n) {
for (j in 2:t) {
# Create random noise for this observation
w.error = rnorm(n = 1, mean = 0, sd = 1)
# Compute the current value based on the previous value and the current noise
x[j] <- x[j - 1] + w.error
}
simulation[i] <- x
}
View(simulation)
x
Acf(
data$NETFLIX,
lag.max = 12
)
Pacf(
data$NETFLIX,
lag.max = 12
)
Acf(
data$APPLE,
lag.max = 12
)
Acf(
data$FORD,
lag.max = 12
)
Acf(
data$NETFLIX,
lag.max = 12
)
Acf(
data$APPLE,
lag.max = 12
)
Pacf(
data$APPLE,
lag.max = 12
)
str(data)
data$DATE<- as.Date(paste(data$DATE,sep="/"))
# Load data
data <- read.csv("data_assign_p3.csv")
data$DATE<- format(as.Date(data$DATE), "%d/%m/%Y")
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
library(TSstudio)
library(stringr)
library(zoo)
library(ggplot2)
library(tseries)
library(stats)
library(lmtest)
library(Metrics)
library(dynlm)
library(dLagM)
library(tsoutliers)
# Load data
data <- read.csv("data_assign_p3.csv")
data$DATE<- strftime(strptime(data$DATE,"%d/%m/%y"),"%d/%m/%Y")
str(data)
data$DATE<- strptime(data$DATE,"%d/%m/%y")
str/data
str(data)
ggplot(data, aes(DATE, NETLIX)) +
geom_point() +
geom_line()
ggplot(data, aes(DATE, NETfLIX)) +
geom_point() +
geom_line()
ggplot(data, aes(DATE, NETFLIX)) +
geom_point() +
geom_line()
# Load data
data <- read.csv("data_assign_p3.csv")
data$DATE<- as.Date(data$DATE,"%d/%m/%y")
ggplot(data, aes(DATE, NETFLIX)) +
geom_point() +
geom_line()
ggplot(data, aes(DATE, NETFLIX)) +
geom_line()
ggplot(data, aes(DATE, NETFLIX)) +
geom_point()
ggplot(data, aes(x = DATE, y = NETFLIX)) +
geom_point()
# Load data
data <- read.csv("data_assign_p3.csv")
ggplot(data, aes(x = DATE, y = NETFLIX)) +
geom_point()
data$DATE<- as.Date(data$DATE, format = "%d/%m/%Y")
str(data)
ggplot(data, aes(x = DATE, y = NETFLIX)) +
geom_point()
ggplot(data, aes(x = DATE, y = APPLE)) +
geom_point()
ggplot(data, aes(x = DATE, y = APPLE)) +
geom_line()
ggplot(data, aes(x = DATE, y = NETFLIX)) +
geom_line()
netflix <- auto.arima(data$NETFLIX, d = 0, D = 0, max.p = 10, max.q = 10, ic = "aic")
View(netflix)
netflix <- auto.arima(data$NETFLIX, d = 0, D = 0, max.p = 5, max.q = 5, ic = "aic")
View(netflix)
netflix
netflix <- auto.arima(data$NETFLIX, d = 0, D = 0, max.p = 5, max.q = 0, ic = "aic")
netlix
netflix
