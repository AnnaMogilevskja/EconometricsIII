---
title: "Econometrics II - Assignment 5"
author: "Think of something new"
date: "13 Mar 2022"
output:
  pdf_document:
    includes:
      in_header: "preamble.tex"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
library(TSstudio)
library(stringr)
library(zoo)
library(ggplot2)
library(tseries)
library(stats)
library(lmtest)
library(Metrics)
library(dynlm)
library(dLagM)
library(tsoutliers)
```

# Question 1

```{r}
# Load data
data <- read.csv("data_assign_p1.csv")
```

1.) Plot the sample of Dutch GDP quarterly growth rates that you have at your disposal. Report the 12-period sample ACF and PACF functions and comment on their shape. What does the sample ACF tells you about the dynamic properties of GDP quarterly growth rates?

```{r}
fmt <- "%YQ%q"
data$obs <- as.yearqtr(data$obs, format = fmt)
```


```{r}
ggplot(data, aes(obs, GDP_QGR)) + 
  geom_point() + 
  geom_line() +
  scale_x_yearqtr(format = fmt)
```
```{r}
Acf(
  data$GDP_QGR,
  lag.max = 12
)
```
```{r}
Pacf(
  data$GDP_QGR,
  lag.max = 12
)
```
The ACF is the autocorrelation function and measures the autocorrelation between $X_t$ and $X_{t-h} \forall h$, in our case for $h = \{1, 2, ..., 12\}$. The autocorrelation is an indicator for memory: the higher the correlation, the higher the time dependence. Hence, the ACF also is a good first indicator for the selection of the lags of our time series model (corresponding to the Box-Jenkins approach). The partial autocorrelation function (PACF) goes one step further, controlling for other lags. Looking at our ACF and PACF graphs, we can see that the first lag seem to have a significant effect on our GDP while higher lags have a rather small autocorrelation with $X_t$. 

2.) Estimate an AR(p) model for the same time-series. Please use the general-to-specific modeling approach by starting with a total p = 4 lags and removing insignificant lags sequentially. Report the final estimated AR(p) model, working at a 5% significance level. Comment on the estimated coefficients. What do these coefficients tell you about the dynamic properties of the GDP quarterly growth rate?


```{r}
ar4 <- arima(data$GDP_QGR, order = c(4,0,0))
coeftest(ar4)
```

```{r}
ar3 <- arima(data$GDP_QGR, order = c(3,0,0))
coeftest(ar3)
```

```{r}
ar2 <- arima(data$GDP_QGR, order = c(2,0,0))
coeftest(ar2)
```

```{r}
ar1 <- arima(data$GDP_QGR, order = c(1,0,0))
coeftest(ar1)
```
As only the estimator of the first lag has a significant effect (which can be observed in all model specification), our final model specification is an AR(1) model. The estimator is around $0.27191$. Hence, an increase in the previous period's GDP growth by $1\%$, increases the next period's GDP growth by approximately $0.22\%$. 

3.) Check the regression residuals of the estimated AR(p) model for autocorrelation by plotting the estimated residual ACF function. Does the model seem well specified?
```{r}
checkresiduals(ar1)
```
There is no autocorrelation between the regression residuals of the estimated AR(1) model. Therefore, the model seems to be well specified. 

4.) Make use of your estimated AR model to produce a 2-year (8 quarters) forecast for the Dutch GDP quarterly growth rate that spans until the first quarter of 2011. Report the values you obtained and explain how you derived them.
```{r}
seriesdata <- ts(data$GDP_QGR, start= c(1987, 2), end = c(2009, 1), frequency = 4)
forecast1 <- ts(predict(ar1, n.ahead=8)$pred, start = c(2009,2), frequency = 4)
forecast1
```


```{r}
ts.plot(forecast1, type="l")
```
We used the function predict() to forecast the next 8 quarters based on the AR(1) model. It gives us a time series of predictions, using finite-history prediction (https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/predict.Arima).
The algorithm is based on the Kalman filter (https://www.jstor.org/stable/pdf/2347987.pdf?casa_token=YM8e7AtkQeUAAAAA:iKQiv7RxaEzEBcvzWiMcCKERAXdYmC8XT1hnKuhGYsgsr53gT48e2qJex4rkupEafCimogVYWp1sLz9KmYjUiH-nVpbYCgoiOfnbVC-k4UypJenakvI). 

5.)  Suppose that the innovations in your AR model are iid Gaussian. Produce 95% confidence intervals for your 2-year forecast. Furthermore, comment on the following statement issued by government officials: “Given the available GDP data, we believe that there is a low probability that the Dutch GDP growth rate will remain negative in the second quarter of 2009.”

Under the assumption that the innovations in the AR(1) model are Gaussian, confidence intervals for the h-step ahead forecast $\hat{X}_{T+h}$ can be produced based on the estimated variance of the corresponding h-step ahead forecast error $\hat{\mathbb{Var}}(e_{T+h})$. For an AR(1)-process it holds that:
$$
\mathbb{Var}(e_{T+h})=\sigma^2(1+\phi^2+\phi^4+\dots+\phi^{2(h-1)})
$$
Since the true variance of the innovations is unknown, it is estimated based on the obtained residuals to the fitted values:

$$
\hat{\sigma}^2=\frac{1}{T-1}\sum^T_{t=2}(x_t-\hat{\alpha}-\hat{\phi}x_{t-1})^2
$$
Under the Gaussianity assumption, the 95%-confidence intervals for $\hat{X}_{T+h}$ then formally read as follows:

$$
\hat{X}_{T+h}\pm1.96\cdot\sqrt{\hat{\mathbb{Var}}(e_{T+h})}
$$
The code below produces and plots the confidence intervals together with the h-step ahead forecasts along the observed time series. The estimated standard deviations of the forecast errors which reflect only innovation uncertainty are obtained from the function predict() described above.

```{r}
ts.plot(seriesdata, xlim = c(1987, 2011))
se1 <- ts(predict(ar1, n.ahead=8)$se, start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
```

```{r}
ts.plot(seriesdata, xlim = c(2005, 2011))
se1 <- ts(predict(ar1, n.ahead=8)$se, start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
```

To comment on the statement we can also leverage the Gaussianity assumption which implies that under the assumption of an AR(1)-process future realizations of  Dutch GDP growth follow the following estimated distribution:

$$
X_{T+h}\sim N\left(\hat{X}_{T+h},\sqrt{\hat{\mathbb{Var}}(e_{T+h})}\right) \Rightarrow X_{T+1}\sim N\left(\hat{\alpha}+\hat{\phi}x_T,\hat{\sigma}\right)
$$

This allows us to estimate the probability that the realization of Dutch GDP growth in the next period, i.e. the second quarter of 2009, will fall below 0%:

```{r}
pnorm(0, mean=forecast1[1], sd = se1[1])
```
Given an estimated probability of 43.16% of a negative realization of Dutch GDP growth, our findings do not support the statement.

6.) Do you find the assumption of iid Gaussian innovations reasonable? How does this affect your answer to the previous question?

To test whether the assumption of iid Gaussian innovations is reasonable we can use a Jarque-Bera test based on the distribution moments of the residuals obtained above.

```{r}
jarque.bera.test(ar1$residuals)
```
Since the test rejects the null hypothesis of normaility the assumption of iid Gaussian innovations is under serious jeopardy and weakens the conclusions drawn based upon this normaility assumption above.

7.) Suppose that 2 years have passed since you delivered your forecasts to the government, in the first quarter of 2009. Compare your point forecasts and confidence bounds with the following actual observed values for the 12 quarters from 2009q2 to 2011q1. Please comment on the accuracy of your forecasts.

The given realizations are plotted alongside the point forecases and confidence bounds below.

```{r}
ts.plot(seriesdata, xlim = c(1987, 2011))
re <- ts(c(-1.63,0.28, 0.33, 0.66, 1.59, 0.51, 0.71, 0.81), start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
points(re, type="l", col=3)
```
```{r}
ts.plot(seriesdata, xlim = c(2005, 2011))
re <- ts(c(-1.63,0.28, 0.33, 0.66, 1.59, 0.51, 0.71, 0.81), start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
points(re, type="l", col=3)
```
At a glance, the AR(1)-model estimated above produces forecasts of reasonable accuracy, though without benchmarking such a statement seems fairly unfounded. At least, the true realization of Dutch GDP growth only lays outside the provided confidence intervals for the one-step ahead forecast, i.e. the second quarter of 2009. Generally, the model yields predictions which lay above the true realizations in the validation sample considered here.

8.) Repeat question 2 above, but this time using a 10% significance level for the general to-specific modeling approach. Use the newly estimated model to produce a 2-year (8 quarters) point forecast of the Dutch GDP quarterly growth rate. Comment on the accuracy of the forecast generated by the newly estimated AR model. Is it better than the model you estimated before?

From the discussion in 2. it directly follows that the G2S model selection procedure selects a AR(3)-model if a 10% significance model is adopted. Its estimation is reported again below.

```{r}
ar3
```
Point forecasts and confidence intervals of the Dutch GDP quarterly growth rate are obtained in the same way as above and plotted alongside the forecast yielded by the estimated AR(1)-model.

```{r}
ts.plot(seriesdata, xlim = c(1987,2011))
forecast3 <- ts(predict(ar3, n.ahead=8)$pred, start = c(2009,2), frequency = 4)
se3 <- ts(predict(ar3, n.ahead=8)$se, start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
points(forecast3, type="l", col=4)
points(forecast3 - 1.96*se3, type="l", col=4, lty=2)
points(forecast3 + 1.96*se3, type="l", col=4, lty=2)
points(re, type="l", col=3)
```
```{r}
ts.plot(seriesdata, xlim = c(2005,2011))
forecast3 <- ts(predict(ar3, n.ahead=8)$pred, start = c(2009,2), frequency = 4)
se3 <- ts(predict(ar3, n.ahead=8)$se, start = c(2009,2), frequency = 4)
points(forecast1, type="l", col=2)
points(forecast1 - 1.96*se1, type="l", col=2, lty=2)
points(forecast1 + 1.96*se1, type="l", col=2, lty=2)
points(forecast3, type="l", col=4)
points(forecast3 - 1.96*se3, type="l", col=4, lty=2)
points(forecast3 + 1.96*se3, type="l", col=4, lty=2)
points(re, type="l", col=3)
```
Judging by the naked eye, the AR(3)-model seems to generate more accurate out-of-sample forecasts than the AR(1)-model. This is also confirmed by consulting the forecast mean squared errors for both models:

```{r}
rmse(re, forecast1)
rmse(re, forecast3)
```

To formally test whether the AR(3)-model produces significantly more accurate forecasts a Diebold-Mariano test for predictive accuracy is calculated (Diebold & Mariano, 1995). Since the test rejects the null hypothesis of equality of prediction mean squared errors at the 5% confidence level, the judgement by naked eye is confirmed.

```{r}
error1 <-  re - forecast1
error3 <- re - forecast3
dm.test(error1, error3)
```


## Question 2

1. Plot the sample of Dutch quarterly unemployment rates and Dutch GDP quarterly growth rates that you have at your disposal. Estimate an AR model for the GDP growth rate and an ADL model for the unemployment rate using the GDP growth rate as an exogenous explanatory variable. Please adopt a general-to-specific methodology for both models by eliminating insignificant lags. For the AR model start with four lags of GDP. For the ADL model start with four lags of each variable. Report the final estimated AR and ADL models, working at a 5% significance level. Comment on the estimated coefficients. What do these coefficients tell you about the dynamic properties of the unemployment rate and the GDP growth rate?

The sample of Dutch quarterly unemployment rates and Dutch GDP quarterly growth rates are plotted below.

```{r}
# Load data
data2 <- read.csv("data_assign_p2.csv")
```

```{r}
fmt <- "%YQ%q"
data2$obs <- as.yearqtr(data2$obs, format = fmt)
```


```{r}
ggplot(data2, aes(obs, GDP_QGR)) + 
  geom_point() + 
  geom_line() +
  scale_x_yearqtr(format = fmt)
```

```{r}
ggplot(data2, aes(obs, UN_RATE)) + 
  geom_point() + 
  geom_line() +
  scale_x_yearqtr(format = fmt)
```

To specify the AR model for the GDP growth rate, the lag order is reduced from $p=4$ until the highest-order lag-coefficient is significant at the 5% significance level. This yields an AR(3)-model whose estimation output is printed below. Evidently, a more thorough specification methodology should be based on (multiple) information criteria, but is omitted here. Furthermore, we also do not allow for holes in the autoregressive lag structure.

```{r}
data3 = data2
data3$GDP_QGR <- ts(data3$GDP_QGR, start = c(1987,2), frequency = 4)
data3$UN_RATE <- ts(data3$UN_RATE, start = c(1987,2), frequency = 4)

gdp4 <- arima(data3$GDP_QGR, order = c(4,0,0))
coeftest(gdp4)
```

```{r}
gdp3 <- arima(data3$GDP_QGR, order = c(3,0,0))
coeftest(gdp3)
```
The estimation output suggests that the unconditional expectation of the GDP growth rate is positive since $\hat{\alpha}$ is significantly greater than zero. Moreover, the estimated autoregressive lag structure suggests that it is driven mainly by autocorrelation of order one and three, since the coefficient of the second-order autoregressive lag is not significantly different from 0.

We apply the same procedure to specify the ADL model for the unemployment rate, working at a 5% significance level. 

```{r}
adl4_4 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:4) + L(data3$GDP_QGR, 0:4))
coeftest(adl4_4)
```
```{r}
adl3_3 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:3) + L(data3$GDP_QGR, 0:3))
coeftest(adl3_3)
```


```{r}
adl3_2 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:3) + L(data3$GDP_QGR, 0:2))
coeftest(adl3_2)
```

```{r}
adl3_1 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:3) + L(data3$GDP_QGR, 0:1))
coeftest(adl3_1)
```

```{r}
adl3_0 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:3) + L(data3$GDP_QGR, 0:0))
coeftest(adl3_0)
```
Since under the ADL(3,0) specification, whose respective estimation output is printed above, the distributed lag coefficient is not significantly different from 0, the G2C methodology would lead us to also conclude an AR(3) model for the unemployment rate. To avoid this, an ADL model with a distributed lag of order one is estimated which points us towards disregarding the autoregressive lag of order 2 which the no longer is significant at the 5% significance level.

```{r}
adl2_0 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, 1:3) + L(data3$GDP_QGR, 1:1))
coeftest(adl2_0)
```
Under final ADL (3,1) model which omits the autoregressive lag of order two and only considers the distributed lag of order one, all estimated coefficients are significant at the 5% significance level.

```{r}
adl3_1 <- dynlm(data3$UN_RATE ~ L(data3$UN_RATE, c(1,3)) + L(data3$GDP_QGR, 1:1))
coeftest(adl3_1)
```
The dynamic properties of the unemployment rate implied by these coefficient estimations seems loosely plausible. First, the fact that the estimated intercept is significantly positive results in a positive unconditional expectation of unemployment which one might interpret as pointing at the fact that the long-run/natural rate of unemployment is positive. Second, the fact that the lagged  rather than current GDP growth is negatively related with unemployment rates is in line with frictional notions of the labor market which results in productivity/output shocks to affect unemployment with some delay.

2) Use the estimated ADL model to calculate and interpret the short-run multiplier, the 2-step-ahead multiplier, and the long-run multiplier. Finally, report and interpret the long-run relation between the unemployment rate and the GDP growth rate.

The final ADL model specification estimated above reads as follows were $Y_t$ referes to the unemployment rate in period $t$ and $X_t$ refers to the GDP growth rate in period $t$ (both measured in percentage points).

$$
Y_t=\alpha+\phi_1Y_{t-1}+\phi_3Y_{t-3}+\beta X_{t-1}+\varepsilon_t
$$
Multiplier estimations are concerned with the effect of a unit shock to $X_t$ on the value of $Y_t$ in different periods. Since under the ADL-model considered here $Y_t$ and $X_t$ are independent, the short-run multiplier is evidently assumed to be 0.

The 2-step-ahead multiplier is obtained by iteratively applying the model specification above where $X^*_t=X_t+1$ and the multiplier of the h'th step equals $Y^*_{t+h}-Y_{t+h}$ where for $Y^*_t$ the shock to $X_t$ reflected by $X^*_t$ propagates through the system. From above we thus know that $Y^*_t=Y_t$. Furthermore:

\begin{equation*}
\begin{split}
  Y^*_{t+1}&=\alpha+\phi_1 Y^*_t+\phi_3Y_{t-2}+\beta X^*_t+\varepsilon_{t+1}\\
  &=\alpha+\phi_1 Y_t+\phi_3Y_{t-2}+\beta (X_t+1)+\varepsilon_{t+1}=Y_{t+1}+\beta\\
  Y^*_{t+2}&=\alpha+\phi_1 Y^*_{t+1}+\phi_3Y_{t-1}+\beta X_{t-1}+\varepsilon_{t+2}\\
  &=\alpha+\phi_1(Y_{t+1}+\beta)+\phi_3Y_{t-1}+\beta X_{t-1}+\varepsilon_{t+2}=Y_{t+2}+\phi_1\beta
\end{split}
\end{equation*}

The estimated 2-step-ahead multiplier therefore equals $\hat{\phi}_1\hat{\beta}$:

```{r}
as.numeric(adl3_1$coefficients[2]*adl3_1$coefficients[4])
```
The long-run relation between the unemployment rate $\bar{Y}$ and the GDP growth rate $\bar{X}$ reads as follows where $\gamma_1$ corresponds to the long-run multiplier.

$$
\bar{Y}=\alpha+\phi_1\bar{Y}+\phi_3\bar{Y}+\beta\bar{Y} \Rightarrow \bar{Y}=\frac{\alpha}{1-\phi_1-\phi_3}+\frac{\beta}{1-\phi_1-\phi_3}\bar{X}\equiv\gamma_1+\gamma_2\bar{X}
$$
The coefficients of this long-run relationship $\gamma_1$ and $\gamma_2$ are estimated as respectively reported below:

```{r}
as.numeric(adl3_1$coefficients[1]/(1-adl3_1$coefficients[2]-adl3_1$coefficients[3]))
as.numeric(adl3_1$coefficients[4]/(1-adl3_1$coefficients[2]-adl3_1$coefficients[3]))
```
This estimated long-run relationship gives an estimation of Okun's law and shows how an ADL-model estimation implies an estimation of Okun's law. The parameter estimation obtained above implies that a one-percentage-point increase in the long-run GDP growth rate is associated with a -0.8519962 percentage point decrease in the long-run unemployment rate. Furthermore, if long-run output were to be constant, i.e.  $\bar{X}=0$, the long-run unemployment rate would be 6.526205%.

To verify the convergence of impulse response functions we can obtain an estimate for the unconditional expectation of the GDP growth rate, i.e. $\bar{X}=\mathbb{E}(X_t)$, as implied by the AR(3)-model specified above to obtain an estimate for the unconditional expectation of the unemployment rate. More specifically we have that:

$$
X_t=\kappa+\psi_1X_{t-1}+\psi_2X_{t-2}+\psi_3X_{t-3} \Rightarrow \mathbb{E}(X_t)=\bar{X}=\frac{\kappa}{1-\psi_1-\psi_2-\psi_3}
$$
Which is estimated to equal:
```{r}
as.numeric(gdp3$coef[4]/(1-gdp3$coef[1]-gdp3$coef[2]-gdp3$coef[3]))
```
Plugging in the expression for $\bar{X}$ into the long-run relationship above yields the estimated long-run unemployment rate:

$$
\Rightarrow \bar{X}=\frac{\alpha}{1-\phi_1-\phi_3}+\frac{\beta}{1-\phi_1-\phi_3}\frac{\kappa}{1-\psi_1-\psi_2-\psi_3}
$$

Which is estimated to equal:
```{r}
as.numeric(adl3_1$coefficients[1]/(1-adl3_1$coefficients[2]-adl3_1$coefficients[3])) + as.numeric(adl3_1$coefficients[4]/(1-adl3_1$coefficients[2]-adl3_1$coefficients[3])) * as.numeric(gdp3$coef[4]/(1-gdp3$coef[1]-gdp3$coef[2]-gdp3$coef[3]))
```

3) Please provide a detailed comment on the following statement: “An increase in the GDP growth rate causes a reduction in the unemployment rate.”

As described above, the obtained estimation of Okun's law indeed suggestst that a permanent increase in the (long-run) GDP growth rate causes a permanent decrease in the (long-run) unemployment rate. This must however be contrasted with a temporary or one-off increase in the GDP growth rate, which leads to a decrease in the unemployment rate in the subsequent quarters (i.e. with a lag) but not to a permanent decrease. Rather, absent further shocks to the GDP growth rate, the unemployment rate will converge (back) to its long-run level estimated above. This notion will also become clear visually when inspecting the impulse response function for the unemployment rate below.

4) Suppose that the innovations are iid Gaussian. What is the probability of the unemployment rate rising above 7.8% in the second quarter of 2014? What is the probability that it drops below 7.8%? Do you trust the iid Gaussian assumption?

```{r}
h = 8
forecast_ar <-predict(gdp3, n.ahead=h)$pred
forecast_ar
forecast_ar <- as.numeric(forecast_ar)

GDP_QGR <- append(as.numeric(data2$GDP_QGR), forecast_ar)
UN_RATE <- append(as.numeric(data2$UN_RATE), numeric(h))
```

```{r}
n <- length(data2$obs)
for (i in 1:h){
  j = i + n
  UN_RATE[j] <- adl3_1$coefficient[1] + adl3_1$coefficient[2] * UN_RATE[j-1] + adl3_1$coefficient[3] * UN_RATE[j-3] + adl3_1$coefficient[4] * GDP_QGR[j-1]
}
```

```{r}
fe1 <- summary(adl3_1)$sigma
```
```{r}
"The probability that it is below 7.8:"
pnorm(7.8, mean = UN_RATE[109], sd = fe1)
"The probability that it is above 7.8:"
1 - pnorm(7.8, mean = UN_RATE[109], sd = fe1)
```

```{r}
jarque.bera.test(adl3_1$residuals)
```

5) Make use of your estimated AR and ADL models to produce a 2-year (8 quarter) forecast for the Unemployment rate that spans until the first quarter of 2016. Report the obtained values.

```{r}
UN$test
```


```{r}
UN_RATE <- ts(UN_RATE, start = c(1987, 2), frequency = 4)
UN <- ts_split(UN_RATE, sample.out = h)
```


```{r}
ts.plot(UN$train, xlim = c(1987, 2017))
points(UN$test, type="l", col=2)
```

```{r}
ts.plot(UN$train, xlim = c(2000, 2017))
points(UN$test, type="l", col=2)
```

6) Use impulse response functions (IRFs) to analyze two different scenarios for the Dutch unemployment rate:
(a) In the ‘good scenario’ the GDP quarterly growth rate is hit by a positive shock of 2%.
(b) In the ‘bad scenario’ the GDP quarterly growth rate suffers a negative shock of 2%.
Please use the last observed value of the unemployment rate and gdp growth rate as the origin of your IRFs. In particular, set the origin to -0.37% for GDP and 7.8% for the unemployment rate.

# Good Scenario

```{r}
h = 200
GDP_QGR <- append(rep(data2$GDP_QGR[n],3), numeric(h))
UN_RATE <- append(rep(data2$UN_RATE[n],3), numeric(h))
```

```{r}
GDP_QGR[3+1] = 2
for (i in 1:h){
  j = i + 3
  GDP_QGR[j] <- GDP_QGR[j] + ar3$coef[4] + ar3$coef[1] * GDP_QGR[j-1] + ar3$coef[2] * GDP_QGR[j-2] + ar3$coef[3] * GDP_QGR[j-3]
}
```

```{r}
n <- length(data2$obs)
for (i in 1:h){
  j = i + 3
  UN_RATE[j] <- adl3_1$coefficient[1] + adl3_1$coefficient[2] * UN_RATE[j-1] + adl3_1$coefficient[3] * UN_RATE[j-3] + adl3_1$coefficient[4] * GDP_QGR[j-1]
}
```

```{r}
UN_RATE <- ts(UN_RATE, start = c(2013, 3), frequency = 4)
```

```{r}
ts.plot(UN_RATE)
```


# Bad Scenario
```{r}
h = 200
GDP_QGR <- append(rep(data2$GDP_QGR[n],3), numeric(h))
UN_RATE <- append(rep(data2$UN_RATE[n],3), numeric(h))
```

```{r}
GDP_QGR[3+1] = -2
for (i in 1:h){
  j = i + 3
  GDP_QGR[j] <- GDP_QGR[j] + ar3$coef[4] + ar3$coef[1] * GDP_QGR[j-1] + ar3$coef[2] * GDP_QGR[j-2] + ar3$coef[3] * GDP_QGR[j-3]
}
```

```{r}
n <- length(data2$obs)
for (i in 1:h){
  j = i + 3
  UN_RATE[j] <- adl3_1$coefficient[1] + adl3_1$coefficient[2] * UN_RATE[j-1] + adl3_1$coefficient[3] * UN_RATE[j-3] + adl3_1$coefficient[4] * GDP_QGR[j-1]
}
```

```{r}
UN_RATE <- ts(UN_RATE, start = c(2013, 3), frequency = 4)
```

```{r}
ts.plot(UN_RATE)
```

