arima(x=ts, order = c(max_lag -1,0,0), fixed = lag_struc[which.min(aics),], method ="CSS")
# Perform ADF Test
ts <- ts(ts)
struc <- c(0)
for (i in 1:length(lag_struc[which.min(aics),]-1)){
if (is.na(lag_struc[which.min(aics),i])){
struc <- cbind(struc, i)
}
}
struc <- as.numeric(struc[,-1])
if(is.na(lag_struc[which.min(aics),i])){
int = TRUE
mod <- dynlm(diff(ts) ~ L(ts,1) + L(diff(ts),struc))
} else{
int = FALSE
mod <- dynlm(diff(ts) ~ L(ts,1) + L(diff(ts),struc)-1)
}
beta = summary(mod)$coefficients[1,1]
se = summary(mod)$coefficients[1,2]
adf = beta / se
adf
if(int==TRUE){
adf< (-1.616)
}else{
adf< (-2.568)
}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Estimate all models and pick specification with highest AIC - SP500
ts <- data$SP500
aics <- rep(0, comb)
for (i in 1:comb){
logl <- arima(x=ts, order = c(max_lag -1,0,0), fixed = lag_struc[i,], method ="CSS")$loglik
k = sum(is.na(lag_struc[i,]))
aics[i] = 2*k - 2*logl
}
min(aics)
arima(x=ts, order = c(max_lag -1,0,0), fixed = lag_struc[which.min(aics),], method ="CSS")
# Perform ADF Test
ts <- ts(ts)
struc <- c(0)
for (i in 1:length(lag_struc[which.min(aics),]-1)){
if (is.na(lag_struc[which.min(aics),i])){
struc <- cbind(struc, i)
}
}
struc <- as.numeric(struc[,-1])
if(is.na(lag_struc[which.min(aics),i])){
int = TRUE
mod <- dynlm(diff(ts) ~ L(ts,1) + L(diff(ts),struc))
} else{
int = FALSE
mod <- dynlm(diff(ts) ~ L(ts,1) + L(diff(ts),struc)-1)
}
beta = summary(mod)$coefficients[1,1]
se = summary(mod)$coefficients[1,2]
adf = beta / se
adf
if(int==TRUE){
adf< (-1.616)
}else{
adf< (-2.568)
}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Estimate all models and pick specification with highest AIC - YAHOO
ts <- data$YAHOO
aics <- rep(0, comb)
for (i in 1:comb){
logl <- arima(x=ts, order = c(max_lag -1,0,0), fixed = lag_struc[i,], method ="CSS")$loglik
k = sum(is.na(lag_struc[i,]))
aics[i] = 2*k - 2*logl
}
min(aics)
arima(x=ts, order = c(max_lag -1,0,0), fixed = lag_struc[which.min(aics),], method ="CSS")
<<<<<<< HEAD
# Perform ADF Test
ts <- ts(ts)
struc <- c(0)
for (i in 1:length(lag_struc[which.min(aics),]-1)){
if (is.na(lag_struc[which.min(aics),i])){
struc <- cbind(struc, i)
}
}
struc <- as.numeric(struc[,-1])
if(is.na(lag_struc[which.min(aics),i])){
int = TRUE
mod <- dynlm(diff(ts) ~ L(ts,1) + L(diff(ts),struc))
} else{
int = FALSE
mod <- dynlm(diff(ts) ~ L(ts,1) + L(diff(ts),struc)-1)
}
beta = summary(mod)$coefficients[1,1]
se = summary(mod)$coefficients[1,2]
adf = beta / se
adf
if(int==TRUE){
adf< (-1.616)
}else{
adf< (-2.568)
}
View(comb_set)
View(data)
sum(diff(data$APPLE))
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Estimate sigma for APPLE & MICROSOFT
sigma_apple = sum(diff(data$APPLE)^2) / (length(diff(data$APPLE)))
ts.plot(data$APPLE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
data$DATE<- as.Date(data$DATE, format = "%d/%m/%Y")
ts.plot(data$APPLE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Estimate sigma for APPLE & MICROSOFT
sigma_aapl = sum(diff(data$APPLE)^2) / (length(diff(data$APPLE)))
sigma_msft = sum(diff(data$MICROSOFT)^2) / (length(diff(data$MICROSOFT)))
# Store last 10 observations for each stock price
hist_aapl <- tail(data$APPLE,10)
ts.plot(hist_aapl)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Estimate sigma for APPLE & MICROSOFT
sigma_aapl = sum(diff(data$APPLE)^2) / (length(diff(data$APPLE)))
sigma_msft = sum(diff(data$MICROSOFT)^2) / (length(diff(data$MICROSOFT)))
# Store last h observations for each stock price
t = 20
hist_aapl <- tail(data$APPLE,t)
hist_msft <- tail(data$MICROSOFT,t)
# Produce forecast
h = 5
forecast_aapl <-  numeric(h)
forevast_msft <- numeric(h)
forecast_aapl[1] = tail(data$APPLE,1)
forevast_msft[1] = tail(data$MICROSOFT,1)
for (i in 2:h){
forecast_aapl[i] = forecast_aapl[i-1]
forevast_msft[i] = forevast_msft[i-1]
}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Generate plot APPLE
ts.plot(hist_aapl)
points(forecast_aapl, type="l", col=2)
points(forecast_aapl - 1.96*sqrt(sigma_aapl), type="l", col=2, lty=2)
points(forecast_aapl + 1.96*sqrt(sigma_aapl), type="l", col=2, lty=2)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Estimate sigma for APPLE & MICROSOFT
sigma_aapl = sum(diff(data$APPLE)^2) / (length(diff(data$APPLE)))
sigma_msft = sum(diff(data$MICROSOFT)^2) / (length(diff(data$MICROSOFT)))
# Store last h observations for each stock price
t = 20
hist_aapl <- tail(data$APPLE,t)
hist_msft <- tail(data$MICROSOFT,t)
# Produce forecast
h = 5
forecast_aapl <-  numeric(h)
forevast_msft <- numeric(h)
forecast_aapl[1] = tail(data$APPLE,1)
forevast_msft[1] = tail(data$MICROSOFT,1)
for (i in 2:h){
forecast_aapl[i] = forecast_aapl[i-1]
forevast_msft[i] = forevast_msft[i-1]
}
forecast_aapl <-  ts(forecast_aapl)
forevast_msft <- ts(forecast_msft)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Estimate sigma for APPLE & MICROSOFT
sigma_aapl = sum(diff(data$APPLE)^2) / (length(diff(data$APPLE)))
sigma_msft = sum(diff(data$MICROSOFT)^2) / (length(diff(data$MICROSOFT)))
# Store last h observations for each stock price
t = 20
hist_aapl <- tail(data$APPLE,t)
hist_msft <- tail(data$MICROSOFT,t)
# Produce forecast
h = 5
forecast_aapl <-  numeric(h)
forevast_msft <- numeric(h)
forecast_aapl[1] = tail(data$APPLE,1)
forevast_msft[1] = tail(data$MICROSOFT,1)
for (i in 2:h){
forecast_aapl[i] = forecast_aapl[i-1]
forevast_msft[i] = forevast_msft[i-1]
}
forecast_aapl <-  ts(forecast_aapl)
forecast_msft <- ts(forecast_msft)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Estimate sigma for APPLE & MICROSOFT
sigma_aapl = sum(diff(data$APPLE)^2) / (length(diff(data$APPLE)))
sigma_msft = sum(diff(data$MICROSOFT)^2) / (length(diff(data$MICROSOFT)))
# Store last h observations for each stock price
t = 20
hist_aapl <- tail(data$APPLE,t)
hist_msft <- tail(data$MICROSOFT,t)
# Produce forecast
h = 5
forecast_aapl <-  numeric(h)
forecast_msft <- numeric(h)
forecast_aapl[1] = tail(data$APPLE,1)
forecast_msft[1] = tail(data$MICROSOFT,1)
for (i in 2:h){
forecast_aapl[i] = forecast_aapl[i-1]
forecast_msft[i] = forevast_msft[i-1]
}
forecast_aapl <-  ts(forecast_aapl)
forecast_msft <- ts(forecast_msft)
# Generate plot APPLE
ts.plot(hist_aapl)
points(forecast_aapl, type="l", col=2)
points(forecast_aapl - 1.96*sqrt(sigma_aapl), type="l", col=2, lty=2)
points(forecast_aapl + 1.96*sqrt(sigma_aapl), type="l", col=2, lty=2)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Estimate sigma for APPLE & MICROSOFT
sigma_aapl = sum(diff(data$APPLE)^2) / (length(diff(data$APPLE)))
sigma_msft = sum(diff(data$MICROSOFT)^2) / (length(diff(data$MICROSOFT)))
# Store last h observations for each stock price
t = 20
hist_aapl <- tail(data$APPLE,t)
hist_msft <- tail(data$MICROSOFT,t)
# Produce forecast
h = 5
forecast_aapl <-  numeric(h)
forecast_msft <- numeric(h)
forecast_aapl[1] = tail(data$APPLE,1)
forecast_msft[1] = tail(data$MICROSOFT,1)
for (i in 2:h){
forecast_aapl[i] = forecast_aapl[i-1]
forecast_msft[i] = forevast_msft[i-1]
}
forecast_aapl <-  ts(forecast_aapl, start = t+1)
forecast_msft <- ts(forecast_msft, start = t+1)
# Generate plot APPLE
ts.plot(hist_aapl)
points(forecast_aapl, type="l", col=2)
points(forecast_aapl - 1.96*sqrt(sigma_aapl), type="l", col=2, lty=2)
points(forecast_aapl + 1.96*sqrt(sigma_aapl), type="l", col=2, lty=2)
ts:plot(forecast_aapl)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Estimate sigma for APPLE & MICROSOFT
sigma_aapl = sum(diff(data$APPLE)^2) / (length(diff(data$APPLE)))
sigma_msft = sum(diff(data$MICROSOFT)^2) / (length(diff(data$MICROSOFT)))
# Store last h observations for each stock price
t = 20
hist_aapl <- tail(data$APPLE,t)
hist_msft <- tail(data$MICROSOFT,t)
# Produce forecast
h = 5
forecast_aapl <-  rep( tail(data$APPLE,1),h)
forecast_msft <- rep( tail(data$MICROSOFT,1),h)
forecast_aapl <-  ts(forecast_aapl, start = t+1)
forecast_msft <- ts(forecast_msft, start = t+1)
# Generate plot APPLE
ts.plot(hist_aapl)
points(forecast_aapl, type="l", col=2)
points(forecast_aapl - 1.96*sqrt(sigma_aapl), type="l", col=2, lty=2)
points(forecast_aapl + 1.96*sqrt(sigma_aapl), type="l", col=2, lty=2)
ts.plot(forecast_aapl)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Generate plot APPLE
ts.plot(forecast_aapl)
points(forecast_aapl - 1.96*sqrt(sigma_aapl), type="l", col=2, lty=2)
points(forecast_aapl + 1.96*sqrt(sigma_aapl), type="l", col=2, lty=2)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Generate plot MICROSOFT
ts.plot(forecast_msft)
points(forecast_msft - 1.96*sqrt(sigma_aapl), type="l", col=2, lty=2)
points(forecast_msft + 1.96*sqrt(sigma_aapl), type="l", col=2, lty=2)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Generate plot MICROSOFT
ts.plot(forecast_msft)
points(forecast_msft - 1.96*sqrt(sigma_msft), type="l", col=2, lty=2)
points(forecast_msft + 1.96*sqrt(sigma_msft), type="l", col=2, lty=2)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
mod <- lm(data$APPLE ~ data$EXXON_MOBIL)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
mod <- lm(data$APPLE ~ data$EXXON_MOBIL)
summary(mod)
=======
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
library(TSstudio)
library(stringr)
library(zoo)
library(ggplot2)
library(tseries)
library(stats)
library(lmtest)
library(Metrics)
library(dynlm)
library(dLagM)
library(tsoutliers)
library(DescTools)
library(naniar)
# Load data
data <- read.csv("data_assign_p3.csv")
# Load data
data <- read.csv("data_assign_p3.csv")
set.seed(1)
t = 100
n = 10000
sigma_u = 1
sigma_v = 1
# Create the first value
x <- data.frame(rnorm(n,0,sigma_v))
y <- data.frame(rnorm(n,0,sigma_u))
# Generate Random walk
for (i in 1:(t-1)){
v <- as.numeric(x[i,]) + rnorm(n,0,sigma_v)
x <- data.frame(x, v)
u <- as.numeric(y[i,]) + rnorm(n,0,sigma_u)
y <- data.frame(y, u)
}
# Run regressions & store beta, SE and R^2
est <- matrix(,nrow = n, ncol =3)
for (i in 1:n){
reg <- summary(lm(as.numeric(y[i,])~ as.numeric(x[i,])))
est[i,1] <- reg$coef[2,1]
est[i,2] <- reg$coef[2,2]
est[i,3] <- reg$r.squared
}
# Plot histograms
plot(density(est[,1])$x,density(est[,1])$y,type="l",xlab="Distribution of estimated betas",ylab="Density")
plot(density(est[,2])$x,density(est[,2])$y,type="l",xlab="Distribution of estimated S.E.",ylab="Density")
plot(density(est[,3])$x,density(est[,3])$y,type="l",xlab="Distribution of R^2",ylab="Density")
data$DATE<- as.Date(data$DATE, format = "%d/%m/%Y")
ggplot(data, aes(x = DATE, y = NETFLIX)) +
geom_line()
ggplot(data, aes(x = DATE, y = APPLE)) +
geom_line()
Acf(
data$NETFLIX,
lag.max = 12
)
Pacf(
data$NETFLIX,
lag.max = 12
)
Acf(
data$APPLE,
lag.max = 12
)
Pacf(
data$APPLE,
lag.max = 12
)
max_lag = 6
lag <- c(1:max_lag)
comb_set <- CombSet(lag, m=1:max_lag)
View(comb_set)
for (i in 1:max_lag){
comb = comb + CombN(max_lag,i)
}
comb = 0
for (i in 1:max_lag){
comb = comb + CombN(max_lag,i)
}
lag_struc <- matrix(0,nrow = comb, ncol =max_lag)
lag_max <- rep(0, comb)
lag_struc
# Lag 1
lag_n = 1
for (i in 1:length(comb_set[[lag_n]])){
lag = comb_set[[lag_n]][i]
lag_struc[i,lag] = NA
}
# Lag 2 and higher
start = 0
for (n in 2:max_lag){
lag_n = n
start = start + length(comb_set[[lag_n-1]][,1])
for (i in 1:length(comb_set[[lag_n]][,1])){
for (j in 1:lag_n){
lag = comb_set[[lag_n]][i,j]
lag_struc[start + i,lag] = NA
}
}
}
# Delete model with only intercept
lag_struc <- lag_struc[-max_lag,]
comb = comb -1
lag_struc
# Set combinatorics where 1 last lag is intercept
max_lag = 6
lag <- c(1:max_lag)
comb_set <- CombSet(lag, m=1:max_lag)
comb = 0
for (i in 1:max_lag){
comb = comb + CombN(max_lag,i)
}
lag_struc <- matrix(0,nrow = comb, ncol =max_lag)
lag_max <- rep(0, comb)
# Lag 1
lag_n = 1
for (i in 1:length(comb_set[[lag_n]])){
lag = comb_set[[lag_n]][i]
lag_struc[i,lag] = NA
}
# Lag 2 and higher
start = 0
for (n in 2:max_lag){
lag_n = n
start = start + length(comb_set[[lag_n-1]][,1])
for (i in 1:length(comb_set[[lag_n]][,1])){
for (j in 1:lag_n){
lag = comb_set[[lag_n]][i,j]
lag_struc[start + i,lag] = NA
}
}
}
# Delete model with only intercept
lag_struc <- lag_struc[-max_lag,]
comb = comb -1
# Estimate all models and pick specification with lowest AIC - APPLE
ts <- data$APPLE
aics <- rep(0, comb)
for (i in 1:comb){
logl <- arima(x=ts, order = c(max_lag -1,0,0), fixed = lag_struc[i,], method ="CSS")$loglik
k = sum(is.na(lag_struc[i,]))
aics[i] = 2*k - 2*logl
}
min(aics)
arima(x=ts, order = c(max_lag -1,0,0), fixed = lag_struc[which.min(aics),], method ="CSS")
# Estimate all models and pick specification with lowest AIC - EXXON_MOBIL
ts <- data$EXXON_MOBIL
aics <- rep(0, comb)
for (i in 1:comb){
logl <- arima(x=ts, order = c(max_lag -1,0,0), fixed = lag_struc[i,], method ="CSS")$loglik
k = sum(is.na(lag_struc[i,]))
aics[i] = 2*k - 2*logl
}
min(aics)
arima(x=ts, order = c(max_lag -1,0,0), fixed = lag_struc[which.min(aics),], method ="CSS")
lag_struc
set.seed(20)
t = 100
n = 10000
sigma_u = 1
sigma_v = 1
gamma = 0.8
phi = 1
# Create the first value
x <- data.frame(rnorm(n,0,sigma_v))
y <- data.frame(rnorm(n,0,sigma_u))
# Generate Random walk
for (i in 1:(t-1)){
v <- as.numeric(x[i,]) + phi * rnorm(n,0,sigma_v)
x <- data.frame(x, v)
u <- as.numeric(x[(i+1),]) + gamma * rnorm(n,0,sigma_u)
y <- data.frame(y, u)
}
# Run regressions & store beta, SE and R^2
est <- matrix(,nrow = n, ncol =3)
for (i in 1:n){
reg <- summary(lm(as.numeric(y[i,])~ as.numeric(x[i,])))
est[i,1] <- reg$coef[2,1]
est[i,2] <- reg$coef[2,2]
est[i,3] <- reg$r.squared
}
# Plot histograms
plot(density(est[,1])$x,density(est[,1])$y,type="l",xlab="Distribution of estimated betas",ylab="Density")
plot(density(est[,2])$x,density(est[,2])$y,type="l",xlab="Distribution of estimated S.E.",ylab="Density")
plot(density(est[,3])$x,density(est[,3])$y,type="l",xlab="Distribution of R^2",ylab="Density")
>>>>>>> 3de8c0523cefac45e8aaba345598434edf024c40
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
library(TSstudio)
library(stringr)
library(zoo)
library(ggplot2)
library(tseries)
library(stats)
library(lmtest)
library(Metrics)
library(dynlm)
library(dLagM)
library(tsoutliers)
library(DescTools)
library(naniar)
library(tseries)
# Estimate all models and pick specification with lowest AIC - APPLE
ts <- data$APPLE
aics <- rep(0, comb)
for (i in 1:comb){
logl <- arima(x=ts, order = c(max_lag -1,0,0), fixed = lag_struc[i,], method ="CSS")$loglik
k = sum(is.na(lag_struc[i,]))
aics[i] = 2*k - 2*logl
}
min(aics)
arima(x=ts, order = c(max_lag -1,0,0), fixed = lag_struc[which.min(aics),], method ="CSS")
# Perform ADF Test
ts <- ts(ts)
struc <- c(0)
for (i in 1:length(lag_struc[which.min(aics),]-1)){
if (is.na(lag_struc[which.min(aics),i])){
struc <- cbind(struc, i)
}
}
struc <- as.numeric(struc[,-1])
struc <- head(struc,-1)
if(is.na(lag_struc[which.min(aics),i])){
int = TRUE
mod <- dynlm(diff(ts) ~ L(ts,1) + L(diff(ts),struc))
} else{
int = FALSE
mod <- dynlm(diff(ts) ~ L(ts,1) + L(diff(ts),struc)-1)
}
beta = summary(mod)$coefficients[1,1]
se = summary(mod)$coefficients[1,2]
adf = beta/se
adf
if(int==TRUE){
adf< (-1.616)
}else{
adf< (-2.568)
}
struc
